{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''<html>\n",
    "    <body>\n",
    "        <h1>Wrangle Report</h1>\n",
    "        <p>A wrangling project typically has three processes. Gathering, Assessing and Cleaning.  As part of my Udacity project, I was able to successfully complete all three processes to create a cleaned master set of the WeRateDogs data.\n",
    "        </p>\n",
    "        <h2>Gathering</h2>\n",
    "        <p>\n",
    "        At the gathering stage, you are tasked to collect data from different sources and load them into dataframes in pandas. You can get this data from files, web scraping or querying API's.In this stage I was able to perform the following;\n",
    "        <ul>\n",
    "        <li>Load CSV file into dataframe using pandas</li>\n",
    "        <li>Download file programmatically using requests</li>\n",
    "        </li> Query Twitter API and read data from JSON file line by line into the dataframe</li>\n",
    "        </ul>\n",
    "        </p>\n",
    "         <h2>Assessing</h2>\n",
    "        <p>\n",
    "        This is the stage where you access the data and determine dirtyness(quality) or tidiness issues that it posesses which may interrupt your work. There are two methods of assessing data;\n",
    "        <ul>\n",
    "        <li>Visually - Examining the dataset manually and spotting various issues</li>\n",
    "        <li>Programmatically - Querying the dataset with code to spot underlying issues</li>\n",
    "        </ul>\n",
    "        </p>\n",
    "        <p>\n",
    "        There are two groups of issues your assessment may reveal: Quality and Tidiness Issues. I was able to discover the following quality and tidiness issues;\n",
    "        <h3>Quality Issues</h3>\n",
    "        <ol>\n",
    "        <li>Timestamp and create_date columns in archive_df and tweet_data are strings</li>\n",
    "        <li>Hard coding of missing dog type and dog name columns entries to \"None\"</li>\n",
    "        <li>HTML tags in source column in archived_df </li>\n",
    "        <li>Missing entries in expanded_url column of archive_df</li>\n",
    "        <li>Hard coding of missing dog type and dog name columns entries to \"None\"</li>\n",
    "        <li>Double values in expanded_url column.</li>\n",
    "        <li>Retweets or replies need to be removed from the dataframe archive_df</li>\n",
    "        <li>Tweet ID in the dataframes are integers</li>\n",
    "        <li>Some columns have the wrong rating</li>\n",
    "        </ol>\n",
    "        <h3>Tidiness Issues</h3>\n",
    "        <ol>\n",
    "        <li>Dog type (e.g. puppo) should be in one column</li>\n",
    "        <li>Retweet count and favourite count should be in archive_df dataframe</li>\n",
    "        </ol>\n",
    "        </p>\n",
    "         <h2>Cleaning</h2>\n",
    "        <p>\n",
    "        At this stage, all the issues identified in the assessment stage are resolved allowing us to have a final, quality and tidy dataset.\n",
    "        </p>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "file = open(\"wrangle_report.html\",\"w\")\n",
    "file.write(text)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
